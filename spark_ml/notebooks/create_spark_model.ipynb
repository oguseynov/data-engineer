{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelIndexer = strIdx_1b3fa02c846a\n",
       "tokenizer = tok_40ec759f5603\n",
       "hashingTF = hashingTF_25f6b22d261e\n",
       "featureIndexer = vecIdx_e68fd4c3fe96\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rf: org.apache.spark.ml.classification.RandomForestClas...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecIdx_e68fd4c3fe96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val labelIndexer = new StringIndexer()\n",
    "    .setInputCol(\"label\")\n",
    "    .setOutputCol(\"indexedLabel\")\n",
    "    .fit(raw_sentiment)\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val featureIndexer = new VectorIndexer()\n",
    "    .setInputCol(hashingTF.getOutputCol)\n",
    "    .setOutputCol(\"indexedFeatures\")\n",
    "    .setMaxCategories(4)\n",
    "\n",
    "val rf = new RandomForestClassifier()\n",
    "    .setLabelCol(labelIndexer.getOutputCol)\n",
    "    .setFeaturesCol(featureIndexer.getOutputCol)\n",
    "    .setNumTrees(10)\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "    .setStages(Array(labelIndexer, tokenizer, hashingTF, featureIndexer, rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_b26c4efe5270\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_b26c4efe5270"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_b26c4efe5270\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_b26c4efe5270"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|indexedLabel|               words|            features|     indexedFeatures|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|         0.0|[@switchfoot, htt...|(1000,[7,14,21,54...|(1000,[7,14,21,54...|[4.43931449741300...|[0.44393144974130...|       1.0|\n",
      "|    0|is upset that he ...|         0.0|[is, upset, that,...|(1000,[170,193,22...|(1000,[170,193,22...|[5.46349235938573...|[0.54634923593857...|       0.0|\n",
      "|    0|@Kenichan I dived...|         0.0|[@kenichan, i, di...|(1000,[10,36,77,1...|(1000,[10,36,77,1...|[5.60297627210827...|[0.56029762721082...|       0.0|\n",
      "|    0|my whole body fee...|         0.0|[my, whole, body,...|(1000,[82,191,296...|(1000,[82,191,296...|[5.50443548555005...|[0.55044354855500...|       0.0|\n",
      "|    0|@nationwideclass ...|         0.0|[@nationwideclass...|(1000,[18,96,130,...|(1000,[18,96,130,...|[5.00477983480453...|[0.50047798348045...|       0.0|\n",
      "|    0|@Kwesidei not the...|         0.0|[@kwesidei, not, ...|(1000,[18,223,710...|(1000,[18,223,710...|[4.88423644978360...|[0.48842364497836...|       1.0|\n",
      "|    0|         Need a hug |         0.0|      [need, a, hug]|(1000,[48,170,537...|(1000,[48,170,537...|[4.88423644978360...|[0.48842364497836...|       1.0|\n",
      "|    0|@LOLTrish hey  lo...|         0.0|[@loltrish, hey, ...|(1000,[139,157,17...|(1000,[139,157,17...|[4.73735323941076...|[0.47373532394107...|       1.0|\n",
      "|    0|@Tatiana_K nope t...|         0.0|[@tatiana_k, nope...|(1000,[48,234,299...|(1000,[48,234,299...|[4.88423644978360...|[0.48842364497836...|       1.0|\n",
      "|    0|@twittera que me ...|         0.0|[@twittera, que, ...|(1000,[161,324,47...|(1000,[161,324,47...|[4.94614153371915...|[0.49461415337191...|       1.0|\n",
      "|    0|spring break in p...|         0.0|[spring, break, i...|(1000,[13,193,301...|(1000,[13,193,301...|[4.88423644978360...|[0.48842364497836...|       1.0|\n",
      "|    0|I just re-pierced...|         0.0|[i, just, re-pier...|(1000,[307,329,47...|(1000,[307,329,47...|[5.50443548555005...|[0.55044354855500...|       0.0|\n",
      "|    0|@caregiving I cou...|         0.0|[@caregiving, i, ...|(1000,[56,202,234...|(1000,[56,202,234...|[5.31733102968485...|[0.53173310296848...|       0.0|\n",
      "|    0|@octolinz16 It it...|         0.0|[@octolinz16, it,...|(1000,[126,230,32...|(1000,[126,230,32...|[4.14293320983222...|[0.41429332098322...|       1.0|\n",
      "|    0|@smarrison i woul...|         0.0|[@smarrison, i, w...|(1000,[18,83,170,...|(1000,[18,83,170,...|[5.12017203584503...|[0.51201720358450...|       0.0|\n",
      "|    0|@iamjazzyfizzle I...|         0.0|[@iamjazzyfizzle,...|(1000,[7,71,202,2...|(1000,[7,71,202,2...|[4.79648460326501...|[0.47964846032650...|       1.0|\n",
      "|    0|Hollis' death sce...|         0.0|[hollis', death, ...|(1000,[2,3,18,82,...|(1000,[2,3,18,82,...|[5.0007142316676,...|[0.50007142316676...|       0.0|\n",
      "|    0|about to file taxes |         0.0|[about, to, file,...|(1000,[108,388,48...|(1000,[108,388,48...|[4.88423644978360...|[0.48842364497836...|       1.0|\n",
      "|    0|@LettyA ahh ive a...|         0.0|[@lettya, ahh, iv...|(1000,[13,107,201...|(1000,[13,107,201...|[4.65614738179131...|[0.46561473817913...|       1.0|\n",
      "|    0|@FakerPattyPattz ...|         0.0|[@fakerpattypattz...|(1000,[53,102,154...|(1000,[53,102,154...|[4.56015534791861...|[0.45601553479186...|       1.0|\n",
      "+-----+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 7 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.5560685502586992|\n",
      "|0.45365076406142696|\n",
      "| 0.4397023727891721|\n",
      "|0.44955645144499445|\n",
      "| 0.4995220165195461|\n",
      "| 0.5115763550216391|\n",
      "| 0.5115763550216391|\n",
      "| 0.5262646760589238|\n",
      "| 0.5115763550216391|\n",
      "| 0.5053858466280851|\n",
      "| 0.5115763550216391|\n",
      "|0.44955645144499445|\n",
      "| 0.4682668970315146|\n",
      "| 0.5857066790167775|\n",
      "|0.48798279641549647|\n",
      "| 0.5203515396734982|\n",
      "|   0.49992857683324|\n",
      "| 0.5115763550216391|\n",
      "|  0.534385261820869|\n",
      "| 0.5439844652081389|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
